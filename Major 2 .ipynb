{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim,nn\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import matplotlib as plt\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from math import log10\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Downloaddata():\n",
    "    import urllib\n",
    "    #import wget\n",
    "    path = \"./\"\n",
    "    tgz_file = \"BSDS300-images.tgz\"\n",
    "    print(\"Data Download Initialing...\")\n",
    "    url = \"http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\"\n",
    "    #wget.download(url)\n",
    "    data = urllib.request.urlretrieve(url,tgz_file)\n",
    "    print(\"Data Download Complete\")\n",
    "    print(\"Data Extraction Initializing...\")\n",
    "    with tarfile.open(tgz_file) as tar:\n",
    "        for item in tar:\n",
    "            tar.extract(item,path)\n",
    "    print(\"Data Extraction Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "    data_dir = \"BSDS300/images\"\n",
    "    if(not os.path.exists(data_dir)):\n",
    "        Downloaddata()\n",
    "    return data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_of_Epoch = 30\n",
    "upscale_Factor = 3\n",
    "batch_Size = 4\n",
    "Learning_Rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\",\".jpg\",\".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('YCbCr')\n",
    "    y,_,_ = img.split()\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self,img_dir,input_transform=None,target_transform=None):\n",
    "        super(DatasetFromFolder,self).__init__()\n",
    "        self.image_filenames = [img_dir+\"/\"+x for x in listdir(img_dir) if is_image_file(x)]\n",
    "        \n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        Input=load_img(self.image_filenames[index])\n",
    "        target = Input.copy()\n",
    "        if self.input_transform:\n",
    "            Input = self.input_transform(Input)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        return Input, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_crop_size(crop_size,upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "def input_transform(crop_size,upscale_factor):\n",
    "    return transforms.Compose([transforms.CenterCrop(crop_size),\n",
    "                               transforms.Resize(crop_size//upscale_factor),\n",
    "                               transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "def target_transform(crop_size,upscale_factor):\n",
    "    return transforms.Compose([transforms.CenterCrop(crop_size),\n",
    "                               transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "def fetch_training_data(upscale_factor):\n",
    "    dataset_dir = dataset()\n",
    "    train_dir = dataset_dir+\"/train/\"\n",
    "    crop_size = valid_crop_size(256,upscale_factor)\n",
    "    \n",
    "    return DatasetFromFolder(train_dir,\n",
    "                             input_transform=input_transform(crop_size,upscale_factor),\n",
    "                             target_transform=target_transform(crop_size,upscale_factor)\n",
    "                            )\n",
    "\n",
    "def fetch_test_Data(upscale_factor):\n",
    "    datasetDir = dataset()\n",
    "    test_dir = datasetDir+\"/test\"\n",
    "    crop_size = valid_crop_size(256,upscale_factor)\n",
    "    \n",
    "    return DatasetFromFolder(test_dir,\n",
    "                            input_transform = input_transform(crop_size,upscale_factor),\n",
    "                            target_transform = target_transform(crop_size,upscale_factor)\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_training_data(upscale_Factor)\n",
    "test_data = fetch_test_Data(upscale_Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=4,shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(test_data,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1,64,(5,5),(1,1),(2,2))\n",
    "        self.conv2 = nn.Conv2d(64,64,(3,3),(1,1),(1,1))\n",
    "        self.conv3 = nn.Conv2d(64,32,(3,3),(1,1),(1,1))\n",
    "        self.conv4 = nn.Conv2d(32,3**2,(3,3),(1,1),(1,1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(3)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.relu(self.conv1(x))\n",
    "        x=self.relu(self.conv2(x))\n",
    "        x=self.relu(self.conv3(x))\n",
    "        x=self.pixel_shuffle(self.conv4(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight,init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight,init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \tTraining Loss: 0.0255 \tPSNR: 21.4474\tAccuracy: 53.619%\n",
      "Epoch 2 \tTraining Loss: 0.0063 \tPSNR: 23.7683\tAccuracy: 59.421%\n",
      "Epoch 3 \tTraining Loss: 0.0045 \tPSNR: 24.6475\tAccuracy: 61.619%\n",
      "Epoch 4 \tTraining Loss: 0.0040 \tPSNR: 25.1416\tAccuracy: 62.854%\n",
      "Epoch 5 \tTraining Loss: 0.0037 \tPSNR: 25.3844\tAccuracy: 63.461%\n",
      "Epoch 6 \tTraining Loss: 0.0037 \tPSNR: 25.1373\tAccuracy: 62.843%\n",
      "Epoch 7 \tTraining Loss: 0.0036 \tPSNR: 25.6141\tAccuracy: 64.035%\n",
      "Epoch 8 \tTraining Loss: 0.0036 \tPSNR: 25.6396\tAccuracy: 64.099%\n",
      "Epoch 9 \tTraining Loss: 0.0035 \tPSNR: 25.7738\tAccuracy: 64.435%\n",
      "Epoch 10 \tTraining Loss: 0.0034 \tPSNR: 25.6628\tAccuracy: 64.157%\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "epoch=10\n",
    "train_loss = 0.0\n",
    "valid_loss = 0.0\n",
    "accuracy = 0.0\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    for input_image,target_image  in enumerate(train_loader,1):\n",
    "        input_image,target_image = target_image[0].to(device),target_image[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(input_image),target_image)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    for test_batch in test_data:\n",
    "        input_image,target_image = test_batch[0].to(device),test_batch[1].to(device)\n",
    "        output = model(input_image)\n",
    "        loss = criterion(output,target_image)\n",
    "        psnr = 10*log10(1/loss.item())\n",
    "        valid_loss += psnr\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(test_data)\n",
    "    accuracy = (valid_loss/40.0)*100\n",
    "    print(\"Epoch {} \\tTraining Loss: {:.4f} \\tPSNR: {:.4f}\\tAccuracy: {:.3f}%\".format((i+1),train_loss,valid_loss,accuracy))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
